{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing the Keras Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Objectives**\n",
    "  1. Build a DNN model using the Keras Sequential API\n",
    "  1. Learn how to train a model with Keras\n",
    "  1. Learn how to save/load, and deploy a Keras model on GCP\n",
    "  1. Learn how to deploy and make predictions with the Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Keras sequential API](https://keras.io/models/sequential/) allows you to create Tensorflow models layer-by-layer. This is useful for building most kinds of machine learning models but it does not allow you to create models that share layers, re-use layers or have multiple inputs or outputs. \n",
    "\n",
    "In this lab, we'll see how to build a simple deep neural network model using the Keras sequential api. Once we have trained our model, we will deploy it using Vertex AI and see how to call our model for online prediciton.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the necessary libraries for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.5\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from google.cloud import aiplatform\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "print(tf.__version__)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the taxifare dataset, using the CSV files that we created in the first notebook of this sequence. Those files have been saved into `../data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jupyter jupyter 123590 Jul 11 18:42 ../data/taxi-test.csv\n",
      "-rw-r--r-- 1 jupyter jupyter 579055 Jul 11 18:42 ../data/taxi-train.csv\n",
      "-rw-r--r-- 1 jupyter jupyter 123114 Jul 11 18:42 ../data/taxi-valid.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -l ../data/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> ../data/taxi-test.csv <==\n",
      "6.0,2013-03-27 03:35:00 UTC,-73.977672,40.784052,-73.965332,40.801025,2,0\n",
      "19.3,2012-05-10 18:43:16 UTC,-73.954366,40.778924,-74.004094,40.723104,1,1\n",
      "7.5,2014-05-20 23:09:00 UTC,-73.999165,40.738377,-74.003473,40.723862,2,2\n",
      "12.5,2015-02-23 19:51:31 UTC,-73.9652099609375,40.76948165893555,-73.98949432373047,40.739742279052734,1,3\n",
      "10.9,2011-03-19 03:32:00 UTC,-73.99259,40.742957,-73.989908,40.711053,1,4\n",
      "7.0,2012-09-18 12:51:11 UTC,-73.971195,40.751566,-73.975922,40.756361,1,5\n",
      "19.0,2014-05-20 23:09:00 UTC,-73.998392,40.74517,-73.939845,40.74908,1,6\n",
      "8.9,2012-07-18 08:46:08 UTC,-73.997638,40.756541,-73.973303,40.762019,1,7\n",
      "4.5,2010-07-11 20:39:08 UTC,-73.976738,40.751321,-73.986671,40.74883,1,8\n",
      "7.0,2013-12-12 02:16:40 UTC,-73.985024,40.767537,-73.981273,40.779302,1,9\n",
      "\n",
      "==> ../data/taxi-train.csv <==\n",
      "11.3,2011-01-28 20:42:59 UTC,-73.999022,40.739146,-73.990369,40.717866,1,0\n",
      "7.7,2011-06-27 04:28:06 UTC,-73.987443,40.729221,-73.979013,40.758641,1,1\n",
      "10.5,2011-04-03 00:54:53 UTC,-73.982539,40.735725,-73.954797,40.778388,1,2\n",
      "16.2,2009-04-10 04:11:56 UTC,-74.001945,40.740505,-73.91385,40.758559,1,3\n",
      "33.5,2014-02-24 18:22:00 UTC,-73.993372,40.753382,-73.8609,40.732897,2,4\n",
      "6.9,2011-12-10 00:25:23 UTC,-73.996237,40.721848,-73.989416,40.718052,1,5\n",
      "6.1,2012-09-01 14:30:19 UTC,-73.977048,40.758461,-73.984899,40.744693,2,6\n",
      "9.5,2012-11-08 13:28:07 UTC,-73.969402,40.757545,-73.950049,40.776079,1,7\n",
      "9.0,2014-07-15 11:37:25 UTC,-73.979318,40.760949,-73.95767,40.773724,1,8\n",
      "3.3,2009-11-09 18:06:58 UTC,-73.955675,40.779154,-73.961172,40.772368,1,9\n",
      "\n",
      "==> ../data/taxi-valid.csv <==\n",
      "5.3,2012-01-03 19:21:35 UTC,-73.962627,40.763214,-73.973485,40.753353,1,0\n",
      "25.3,2010-09-27 07:30:15 UTC,-73.965799,40.794243,-73.927134,40.852261,3,1\n",
      "27.5,2015-05-19 00:40:02 UTC,-73.86344146728516,40.76899719238281,-73.96058654785156,40.76129913330078,1,2\n",
      "5.7,2010-04-29 12:28:00 UTC,-73.989255,40.738912,-73.97558,40.749172,1,3\n",
      "11.5,2013-06-23 06:08:09 UTC,-73.99731,40.763735,-73.955657,40.768141,1,4\n",
      "18.0,2014-10-14 18:52:03 UTC,-73.997995,40.761638,-74.008985,40.712442,1,5\n",
      "4.9,2010-04-29 12:28:00 UTC,-73.977315,40.766182,-73.970845,40.761462,5,6\n",
      "32.33,2014-02-24 18:22:00 UTC,-73.985358,40.761352,-73.92427,40.699145,1,7\n",
      "17.0,2015-03-26 02:48:58 UTC,-73.93981170654297,40.846473693847656,-73.97361755371094,40.786983489990234,1,8\n",
      "12.5,2013-04-09 09:39:13 UTC,-73.977323,40.753934,-74.00719,40.741472,1,9\n"
     ]
    }
   ],
   "source": [
    "!head ../data/taxi*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use tf.data to read the CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrote these functions for reading data from the csv files above in the [previous notebook](./2a_dataset_api.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 17:21:22.697182: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-07-13 17:21:22.697251: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-13 17:21:22.697306: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (hurb-asl): /proc/driver/nvidia/version does not exist\n",
      "2022-07-13 17:21:22.697978: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-13 17:21:22.882912: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-73.99902   40.739147 -73.99037   40.717865]\n",
      " [-73.98744   40.72922  -73.97901   40.75864 ]\n",
      " [-73.98254   40.735725 -73.954796  40.77839 ]\n",
      " [-74.001945  40.740505 -73.91385   40.75856 ]\n",
      " [-73.99337   40.753384 -73.8609    40.7329  ]\n",
      " [-73.99624   40.721848 -73.98942   40.718052]\n",
      " [-73.97705   40.75846  -73.9849    40.744694]\n",
      " [-73.9694    40.757545 -73.95005   40.776077]], shape=(8, 4), dtype=float32)\n",
      "tf.Tensor([11.3  7.7 10.5 16.2 33.5  6.9  6.1  9.5], shape=(8,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def parse_csv(row):\n",
    "    ds = tf.strings.split(row, \",\")\n",
    "    label = tf.strings.to_number(ds[0])\n",
    "    features = tf.strings.to_number(\n",
    "        ds[2:6]\n",
    "    )  # return pickup and drop off location only\n",
    "    return features, label\n",
    "\n",
    "\n",
    "def create_dataset(pattern, batch_size):\n",
    "    ds = tf.data.TextLineDataset(pattern)\n",
    "    ds = ds.map(parse_csv).batch(batch_size)\n",
    "    return ds\n",
    "\n",
    "\n",
    "for (feature, label) in create_dataset(\"../data/taxi-train.csv\", 8).take(1):\n",
    "    print(feature)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a simple keras DNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the DNN model. The Sequential model is a linear stack of layers and when building a model using the Sequential API, you configure each layer of the model in turn. Once all the layers have been added, you compile the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Create a deep neural network using Keras's Sequential API. In the cell below, use the `tf.keras.layers` library to create all the layers for your deep neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a keras DNN model using Sequential API\n",
    "# TODO: Your code here\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(\n",
    "            units=32, input_shape=(4,), activation=\"relu\", name=\"input\"\n",
    "        ),\n",
    "        tf.keras.layers.Dense(units=8, activation=\"relu\", name=\"hidden\"),\n",
    "        tf.keras.layers.Dense(units=1, activation=\"linear\", name=\"output\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, to prepare the model for training, you must configure the learning process. This is done using the compile method. The compile method takes three arguments:\n",
    "\n",
    "* An optimizer. This could be the string identifier of an existing optimizer (such as `rmsprop` or `adagrad`), or an instance of the [Optimizer class](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/optimizers).\n",
    "* A loss function. This is the objective that the model will try to minimize. It can be the string identifier of an existing loss function from the [Losses class](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/losses) (such as categorical_crossentropy or mse), or it can be a custom objective function.\n",
    "* A list of metrics. For any machine learning problem you will want a set of metrics to evaluate your model. A metric could be the string identifier of an existing metric or a custom metric function.\n",
    "\n",
    "We will add an additional custom metric called `rmse` to our list of metrics which will return the root mean square error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Compile the model you created above. Create a custom loss function called `rmse` which computes the root mean squared error between `y_true` and `y_pred`. Pass this function to the model as an evaluation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom evalution metric\n",
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(\n",
    "        tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "    )  # TODO: Your code here\n",
    "\n",
    "\n",
    "# Compile the keras model\n",
    "# TODO: Your code here\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[rmse, \"mse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train your model, Keras provides two functions that can be used:\n",
    " 1. `.fit()` for training a model for a fixed number of epochs (iterations on a dataset).\n",
    " 2. `.train_on_batch()` runs a single gradient update on a single batch of data. \n",
    " \n",
    "The `.fit()` function works for various formats of data such as Numpy array, list of Tensors tf.data and Python generators. The `.train_on_batch()` method is for more fine-grained control over training and accepts only a single batch of data.\n",
    "\n",
    "Our `create_dataset` function above generates batches of training examples, so we can use `.fit`. \n",
    "\n",
    "We start by setting up some parameters for our training job and create the data generators for the training and validation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainds = create_dataset(pattern=\"../data/taxi-train.csv\", batch_size=32)\n",
    "\n",
    "evalds = create_dataset(pattern=\"../data/taxi-valid.csv\", batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various arguments you can set when calling the [.fit method](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit). Here `x` specifies the input data which in our case is a `tf.data` dataset returning a tuple of (inputs, targets). The `steps_per_epoch` parameter is used to mark the end of training for a single epoch. Here we are training for NUM_EVALS epochs. Lastly, for the `callback` argument we specify a Tensorboard callback so we can inspect Tensorboard after training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** In the cell below, you will train your model. Train your model using `.fit()`, saving the model training output to a variable called `history`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 17:25:09.133182: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-07-13 17:25:09.133316: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2022-07-13 17:25:09.134789: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "     47/Unknown - 1s 4ms/step - loss: 93.0331 - rmse: 9.0970 - mse: 93.0331   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 17:25:09.633175: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-07-13 17:25:09.633231: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2022-07-13 17:25:09.664368: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-07-13 17:25:09.667038: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2022-07-13 17:25:09.672576: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./taxi_trained/train/plugins/profile/2022_07_13_17_25_09\n",
      "\n",
      "2022-07-13 17:25:09.676557: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to ./taxi_trained/train/plugins/profile/2022_07_13_17_25_09/hurb-asl.trace.json.gz\n",
      "2022-07-13 17:25:09.678939: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./taxi_trained/train/plugins/profile/2022_07_13_17_25_09\n",
      "\n",
      "2022-07-13 17:25:09.679214: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to ./taxi_trained/train/plugins/profile/2022_07_13_17_25_09/hurb-asl.memory_profile.json.gz\n",
      "2022-07-13 17:25:09.679690: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./taxi_trained/train/plugins/profile/2022_07_13_17_25_09\n",
      "Dumped tool data for xplane.pb to ./taxi_trained/train/plugins/profile/2022_07_13_17_25_09/hurb-asl.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./taxi_trained/train/plugins/profile/2022_07_13_17_25_09/hurb-asl.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./taxi_trained/train/plugins/profile/2022_07_13_17_25_09/hurb-asl.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./taxi_trained/train/plugins/profile/2022_07_13_17_25_09/hurb-asl.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./taxi_trained/train/plugins/profile/2022_07_13_17_25_09/hurb-asl.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 1s 4ms/step - loss: 96.0072 - rmse: 9.1465 - mse: 96.0072 - val_loss: 110.2070 - val_rmse: 9.7611 - val_mse: 110.2070\n",
      "Epoch 2/10\n",
      "230/230 [==============================] - 1s 3ms/step - loss: 95.9193 - rmse: 9.1421 - mse: 95.9193 - val_loss: 110.2071 - val_rmse: 9.7611 - val_mse: 110.2071\n",
      "Epoch 3/10\n",
      "230/230 [==============================] - 1s 3ms/step - loss: 95.9153 - rmse: 9.1419 - mse: 95.9153 - val_loss: 110.2070 - val_rmse: 9.7613 - val_mse: 110.2070\n",
      "Epoch 4/10\n",
      "230/230 [==============================] - 1s 3ms/step - loss: 95.9109 - rmse: 9.1416 - mse: 95.9109 - val_loss: 110.2070 - val_rmse: 9.7615 - val_mse: 110.2070\n",
      "Epoch 5/10\n",
      "230/230 [==============================] - 1s 3ms/step - loss: 95.9064 - rmse: 9.1414 - mse: 95.9064 - val_loss: 110.2070 - val_rmse: 9.7616 - val_mse: 110.2070\n",
      "Epoch 6/10\n",
      "230/230 [==============================] - 1s 3ms/step - loss: 95.9020 - rmse: 9.1412 - mse: 95.9020 - val_loss: 110.2071 - val_rmse: 9.7618 - val_mse: 110.2071\n",
      "Epoch 7/10\n",
      "230/230 [==============================] - 1s 3ms/step - loss: 95.8980 - rmse: 9.1409 - mse: 95.8980 - val_loss: 110.2071 - val_rmse: 9.7619 - val_mse: 110.2071\n",
      "Epoch 8/10\n",
      "230/230 [==============================] - 1s 3ms/step - loss: 95.8935 - rmse: 9.1407 - mse: 95.8935 - val_loss: 110.2071 - val_rmse: 9.7621 - val_mse: 110.2071\n",
      "Epoch 9/10\n",
      "230/230 [==============================] - 1s 3ms/step - loss: 95.8893 - rmse: 9.1405 - mse: 95.8893 - val_loss: 110.2073 - val_rmse: 9.7622 - val_mse: 110.2073\n",
      "Epoch 10/10\n",
      "230/230 [==============================] - 1s 3ms/step - loss: 95.8859 - rmse: 9.1402 - mse: 95.8859 - val_loss: 110.2075 - val_rmse: 9.7623 - val_mse: 110.2075\n",
      "CPU times: user 18.5 s, sys: 1.7 s, total: 20.2 s\n",
      "Wall time: 7.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LOGDIR = \"./taxi_trained\"\n",
    "history = model.fit(\n",
    "    x=trainds,\n",
    "    epochs=10,\n",
    "    validation_data=evalds,\n",
    "    callbacks=[TensorBoard(LOGDIR)],\n",
    ")  # TODO: Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 22404), started 0:03:32 ago. (Use '!kill 22404' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-665e05f4671b18a3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-665e05f4671b18a3\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./taxi_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%load_ext-level model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've run data through the model, we can call `.summary()` on the model to get a high-level summary of our network. We can also plot the training and evaluation curves for the metrics we computed above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (Dense)                (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running `.fit` (or `.fit_generator`) returns a History object which collects all the events recorded during training. Similar to Tensorboard, we can plot the training and validation curves for the model loss and rmse by accessing these elements of the History object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "RMSE_COLS = [\"rmse\", \"val_rmse\"]\n",
    "\n",
    "pd.DataFrame(history.history)[RMSE_COLS].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LOSS_COLS = [\"loss\", \"val_loss\"]\n",
    "\n",
    "pd.DataFrame(history.history)[LOSS_COLS].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions with our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make predictions with our trained model, we can call the [predict method](https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict), passing to it a dictionary of values. The `steps` parameter determines the total number of steps before declaring the prediction round finished. Here since we have just one example, we set `steps=1` (setting `steps=None` would also work). Note, however, that if x is a `tf.data` dataset or a dataset iterator, and steps is set to None, predict will run until the input dataset is exhausted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.751797]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[-73.982683, 40.742104, -73.983766, 40.755174]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export and deploy our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, making individual predictions is not realistic, because we can't expect client code to have a model object in memory. For others to use our trained model, we'll have to export our model to a file, and expect client code to instantiate the model from that exported file. \n",
    "\n",
    "We'll export the model to a TensorFlow SavedModel format. Once we have a model in this format, we have lots of ways to \"serve\" the model, from a web application, from JavaScript, from mobile applications, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Use `tf.saved_model.save` to export the trained model to a Tensorflow SavedModel format. Reference the [documentation for `tf.saved_model.save`](https://www.tensorflow.org/api_docs/python/tf/saved_model/save) as you fill in the code for the cell below.\n",
    "\n",
    "Next, print the signature of your saved model using the SavedModel Command Line Interface command `saved_model_cli`. You can read more about the command line interface and the `show` and `run` commands it supports in the [documentation here](https://www.tensorflow.org/guide/saved_model#overview_of_commands). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 17:26:19.926225: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./export/savedmodel/20220713172619/assets\n",
      "INFO:tensorflow:Assets written to: ./export/savedmodel/20220713172619/assets\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = \"./export/savedmodel\"\n",
    "shutil.rmtree(OUTPUT_DIR, ignore_errors=True)\n",
    "TIMESTAMP = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "EXPORT_PATH = os.path.join(OUTPUT_DIR, TIMESTAMP)\n",
    "\n",
    "tf.saved_model.save(\n",
    "    # TODO: Your code here\n",
    "    model,\n",
    "    EXPORT_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['input_input'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 4)\n",
      "      name: serving_default_input_input:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['output'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 1)\n",
      "      name: StatefulPartitionedCall:0\n",
      "Method name is: tensorflow/serving/predict\n",
      "./export/savedmodel/20220713172619\n",
      "./export/savedmodel/20220713172619/saved_model.pb\n",
      "./export/savedmodel/20220713172619/variables\n",
      "./export/savedmodel/20220713172619/variables/variables.index\n",
      "./export/savedmodel/20220713172619/variables/variables.data-00000-of-00001\n",
      "./export/savedmodel/20220713172619/assets\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show \\\n",
    "    --tag_set serve \\\n",
    "    --signature_def serving_default \\\n",
    "    --dir {EXPORT_PATH}\n",
    "\n",
    "!find {EXPORT_PATH}\n",
    "os.environ['EXPORT_PATH'] = EXPORT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy our model to Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will deploy our trained model to Vertex AI and see how we can make online predicitons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "flake8-noqa-line-8-E501"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_DISPLAYNAME: taxifare-20220713172619\n"
     ]
    }
   ],
   "source": [
    "PROJECT = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "PROJECT = PROJECT[0]\n",
    "BUCKET = PROJECT\n",
    "REGION = \"us-central1\"\n",
    "MODEL_DISPLAYNAME = f\"taxifare-{TIMESTAMP}\"\n",
    "\n",
    "print(f\"MODEL_DISPLAYNAME: {MODEL_DISPLAYNAME}\")\n",
    "\n",
    "# from https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers\n",
    "SERVING_CONTAINER_IMAGE_URI = (\n",
    "    \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-3:latest\"\n",
    ")\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket exists, let's not recreate it.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Create GCS bucket if it doesn't exist already...\n",
    "exists=$(gsutil ls -d | grep -w gs://${BUCKET}/)\n",
    "\n",
    "if [ -n \"$exists\" ]; then\n",
    "    echo -e \"Bucket exists, let's not recreate it.\"\n",
    "else\n",
    "    echo \"Creating a new GCS bucket.\"\n",
    "    gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "    echo \"\\nHere are your current buckets:\"\n",
    "    gsutil ls\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./export/savedmodel/20220713172619/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./export/savedmodel/20220713172619/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./export/savedmodel/20220713172619/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "/ [3 files][ 99.0 KiB/ 99.0 KiB]                                                \n",
      "Operation completed over 3 objects/99.0 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -R $EXPORT_PATH gs://$BUCKET/$MODEL_DISPLAYNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Complete the code in the cell below to upload and deploy your trained model to Vertex AI using the `Model.upload` method. Have a look at [the documentation](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.Model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Model\n",
      "INFO:google.cloud.aiplatform.models:Create Model backing LRO: projects/464686547413/locations/us-central1/models/2847765902265417728/operations/3376005991584759808\n",
      "INFO:google.cloud.aiplatform.models:Model created. Resource name: projects/464686547413/locations/us-central1/models/2847765902265417728\n",
      "INFO:google.cloud.aiplatform.models:To use this Model in another session:\n",
      "INFO:google.cloud.aiplatform.models:model = aiplatform.Model('projects/464686547413/locations/us-central1/models/2847765902265417728')\n"
     ]
    }
   ],
   "source": [
    "uploaded_model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_DISPLAYNAME,\n",
    "    artifact_uri=f\"gs://{BUCKET}/{MODEL_DISPLAYNAME}\",  # TODO: Your code here\n",
    "    serving_container_image_uri=SERVING_CONTAINER_IMAGE_URI,  # TODO: Your code here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Endpoint\n",
      "INFO:google.cloud.aiplatform.models:Create Endpoint backing LRO: projects/464686547413/locations/us-central1/endpoints/1521609743632695296/operations/3439056386367946752\n",
      "INFO:google.cloud.aiplatform.models:Endpoint created. Resource name: projects/464686547413/locations/us-central1/endpoints/1521609743632695296\n",
      "INFO:google.cloud.aiplatform.models:To use this Endpoint in another session:\n",
      "INFO:google.cloud.aiplatform.models:endpoint = aiplatform.Endpoint('projects/464686547413/locations/us-central1/endpoints/1521609743632695296')\n",
      "INFO:google.cloud.aiplatform.models:Deploying model to Endpoint : projects/464686547413/locations/us-central1/endpoints/1521609743632695296\n",
      "INFO:google.cloud.aiplatform.models:Deploy Endpoint model backing LRO: projects/464686547413/locations/us-central1/endpoints/1521609743632695296/operations/8717275149646168064\n",
      "INFO:google.cloud.aiplatform.models:Endpoint model deployed. Resource name: projects/464686547413/locations/us-central1/endpoints/1521609743632695296\n"
     ]
    }
   ],
   "source": [
    "MACHINE_TYPE = \"n1-standard-2\"\n",
    "\n",
    "endpoint = uploaded_model.deploy(\n",
    "    machine_type=MACHINE_TYPE,\n",
    "    accelerator_type=None,\n",
    "    accelerator_count=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [],
   "source": [
    "instance = {\"input_layer_input\": [-73.982683, 40.742104, -73.983766, 40.755174]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Complete the code in the cell below to call prediction on your deployed model for the example you just created in the `instance` variable above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "flake8-noqa-cell",
     "flake8-noqa-cell-E902"
    ]
   },
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "400 {\n    \"error\": \"Failed to process element: 0 key: input_layer_input of 'instances' list. Error: Invalid argument: JSON object: does not have named input: input_layer_input\"\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    945\u001b[0m                                       wait_for_ready, compression)\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"{\n    \"error\": \"Failed to process element: 0 key: input_layer_input of 'instances' list. Error: Invalid argument: JSON object: does not have named input: input_layer_input\"\n}\"\n\tdebug_error_string = \"{\"created\":\"@1657734185.956256096\",\"description\":\"Error received from peer ipv4:142.251.120.95:443\",\"file\":\"/home/conda/feedstock_root/build_artifacts/grpc-split_1656146941531/work/src/core/lib/surface/call.cc\",\"file_line\":966,\"grpc_message\":\"{\\n    \"error\": \"Failed to process element: 0 key: input_layer_input of 'instances' list. Error: Invalid argument: JSON object: does not have named input: input_layer_input\"\\n}\",\"grpc_status\":3}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22166/3470984186.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mendpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, instances, parameters)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         prediction_response = self._prediction_client.predict(\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m         )\n\u001b[1;32m   1135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, request, endpoint, instances, parameters, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrpc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;31m# Done; return the response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: 400 {\n    \"error\": \"Failed to process element: 0 key: input_layer_input of 'instances' list. Error: Invalid argument: JSON object: does not have named input: input_layer_input\"\n}"
     ]
    }
   ],
   "source": [
    "endpoint.predict([instance])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup\n",
    "\n",
    "When deploying a model to an endpoint for online prediction, the minimum `min-replica-count` is 1, and it is charged per node hour. So let's delete the endpoint to reduce unnecessary charges. Before we can delete the endpoint, we first undeploy all attached models... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Undeploying Endpoint model: projects/464686547413/locations/us-central1/endpoints/1521609743632695296\n",
      "INFO:google.cloud.aiplatform.models:Undeploy Endpoint model backing LRO: projects/464686547413/locations/us-central1/endpoints/1521609743632695296/operations/5559125910952607744\n",
      "INFO:google.cloud.aiplatform.models:Endpoint model undeployed. Resource name: projects/464686547413/locations/us-central1/endpoints/1521609743632695296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Endpoint object at 0x7f233d236050> \n",
       "resource name: projects/464686547413/locations/us-central1/endpoints/1521609743632695296"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.undeploy_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...then delete the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.base:Deleting Endpoint : projects/464686547413/locations/us-central1/endpoints/1521609743632695296\n",
      "INFO:google.cloud.aiplatform.base:Delete Endpoint  backing LRO: projects/464686547413/locations/us-central1/operations/8081141702280085504\n",
      "INFO:google.cloud.aiplatform.base:Endpoint deleted. . Resource name: projects/464686547413/locations/us-central1/endpoints/1521609743632695296\n"
     ]
    }
   ],
   "source": [
    "endpoint.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
